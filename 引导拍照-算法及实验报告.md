# 2021科大讯飞AI算法挑战赛——引导拍照

## 赛题描述

随着计算机技术的发展，农业开始步入智能化领域。在农业智能化过程中，通过建立起农业病虫害识别模型摆脱传统的专家进行农业病虫害识别。但在农业病虫害识别模型中，由于使用拍摄工具的主体是人，而农业病虫害识别模型对于需要识别的图像具有一定规范性。由于没有对人在拍摄过程中进行规范性引导，导致了人在拍摄过程中随意拍摄图片，从而造成了实际的农业病虫害识别精度远远小于训练时的精度。为了使人拍摄的农作物图像能够达到农业病虫害识别模型输入的要求，提高实际的农业病虫害识别模型的精度，需要建立起引导拍照模型来辅助人进行图片拍摄。本赛题提供行道树图像，参赛选手需基于提供的样本构建模型，实现对图片进行的引导方向分类，共包含：上、右上、右、右下、下、左下、左和左上八个方向。[赛道链接](http://challenge.xfyun.cn/topic/info?type=guide-photo)

## 算法思想

### 赛题分析

通过对任务与数据集的分析，该赛题的主要挑战来自以下几个方面：

- 数据方面：数据规模小，图片场景不是很丰富；样本类别不均衡，共计 **332** 张图片，具体分布如下表。总的来说数据存在：1.数据量小；2.样本不均衡；3.数据质量不高，如部分数据具有歧义；4.场景相对单调

| 类别   | 上  | 右上 | 右 | 右下 | 下 | 左下 | 左 | 左上 |
| ------ | --- | ---- | -- | ---- | -- | ---- | -- | ---- |
| 标签   | 1   | 2    | 3  | 4    | 5  | 6    | 7  | 8    |
| 数据量 | 113 | 49   | 27 | 15   | 23 | 19   | 33 | 53   |

- 任务方面：该任务的重点在于让算法准确地定位主体目标（树干，树冠）与图片中心的相对位置。实现该目标的挑战在于：1.部分图片的主体目标不明确，如存在多棵树的情况；2.方向敏感，限制了数据增强方式

### 大体思路

#### A.数据扩充

针对该任务，有一个非常简单的扩充方式：对赛方提供的数据依次进行垂直翻转和水平翻转。这样一来，新数据量变为**原来的三倍**，**共996张，且扩充后的数据样本不均衡得到了一定程度的缓解**。值得注意的是，翻转后的图片标签需要相应变化。

- 垂直翻转：上 <-> 下
- 水平翻转：左 <->  右

事实上，还可以通过组合翻转，如先水平翻转后垂直翻转，实现进一步的数据扩充。由于本文方案实测效果不佳，所以仅使用了三倍数据。

#### B.数据增强

前面已经提到，该任务是对方向敏感的，所以限制了数据增强的方式，如需要避免翻转操作，此外旋转的角度也不宜过大。具体的增强方式及顺序如下：

- 高斯模糊（*kernel_size*=3）
- 尺寸缩放 （*size*=(256,256)）
- 随机旋转 （*degrees*=(-15,+15)）
- 随机擦除 （*scale*=(0.01, 0.05), *ratio*=(1.1, 1.3)）

#### C.模型选择

由于该任务为分类任务，图片较少且赛题没有限制模型大小和运行时间，因此选择**Efficientnet-b5**作为本文的实验模型。**值得注意的是，** 在本次比赛中并没有对模型进行针对性的调整，而且也没有使用多模融合的方法去提分。

#### D. 预训练

基于预训练权重可以让训练过程更加稳定，通过这个比赛再次证明了参数初始化对于模型优化的重要性。本文选择的Efficientnet-b5的实现来自于[Github链接](https://github.com/lukemelas/EfficientNet-PyTorch)，在加载预训练权重时，将 `advprop`设置为 `True`，可以加快加载速度。之所以提到这一点，是因为不同实现的预训练权重训练出来的网络有时差异很大。

#### E. 多折融合

本次比赛虽然没使用多模融合，但使用了多折融合的方法去获取最终结果。在本实验中，通过五折交叉验证得到了五个模型，最后根据在验证集的表现挑选其中最好的3个用于融合。之所以不使用所有折，是因为不同折的性能差异较大。**值得注意的是：**本文采用的融合策略是基于**概率平均**的。经过我们的检验，朴素投票有时候取得的结果甚至不如单折高。其原因在于，不同模型对于某些难样本的类间预测概率差异不够大，特别是对于相近的类别，如上和右上。通过概率平均可以一定程度地缓解该问题。

#### F. 测试时增强

在预测过程中对单个样本做多次增强进而得到多个预测结果，然后对这些预测结果进行概率平均得到最终结果。这种预测方式通常作为一种提分技巧，有时在小样本的学习任务中效果显著。

#### G.伪标签

该赛题所提供的测试集也很少，仅150张测试图片，因此在使用 `Accuracy`作为评分依据时，每一个样本的影响相对较大。实际上，在最后的刷榜阶段，排名较前的队伍之间差异都很小，相隔不过2-3个正确样本。在本实验最后，采取了伪标签这种方式作为一种提分技巧，最后提高了1-2个正确样本数。伪标签本质上是将测试集用作现有模型的微调，在实际任务中效果其实很有限，其瓶颈取决于原模型的泛化能力。换个角度来说，伪标签只是增加了训练过程的随机性，特别是对于难样本而言，对于实现类间的低密度分离具有一定作用。

## 实验部分

### 运行环境

依赖包: 见 `requirements.txt`，ps:可能不全，遗漏自补。

硬件:  `NVIDIA V100` *2

软件环境：CUDA 11.0

### 实验设置

| Net             | lr              | lr_scheduler               | optimizer            |
| --------------- | --------------- | -------------------------- | -------------------- |
| Efficientnet-b5 | 1e-3            | MultiStepLR （[30,60,90]） | Adam                 |
| **shape** | **epoch** | **loss**             | **Batch size** |
| (3，256，256)   | 120             | Cross Entropy              | 32                   |

*详细配置，见代码。*

### 训练过程

- Step 1: 准备数据

  本实验所用数据已打包提交，复制到工作目录下，包含四个文件夹和一个 `csv`文件，前者为训练数据，后者为对应的标签索引文件。
- Step 2:修改 `config.py`

```python
data_config['Photo_Guide'] = 'you_path_to_csv/dateset/photo_guide_merge_fake.csv' # 解压后csv文件所在路径
TASK = 'Photo_Guide'
NET_NAME = 'efficientnet-b5'
VERSION = 'v6.0-pretrained-fake' #v6.0-pretrained-new
DEVICE = '0,1' # 根据实际设备显存指定
PRE_TRAINED = False # 设置为True时从断点开始训练，为False时，从头训练。
FOLD_NUM = 5
```

**提醒!!!**：提交代码的工作目录中已经包含训练好的模型权重，在 `PRE_TRAINED=False`的设置下启动训练会直接删除文件夹下的权重，若需要恢复现场，将 `模型权重`下的 `ckpt`文件夹复制到工作目录下即可。

- Step 3: 启动训练脚本 `run.py`

  ```shell
  python run.py -m train-cross
  ```
- Step 4: 选择权重：挑选表现最好的三折记录索引，如[1,2,5]

### 预测过程

- Step 1: 准备权重

  本实验最终权重已打包提交，复制到工作目录下即可，一共包含三个权重文件。
- Step 2: 修改 `config.py`

  ```python
  PRE_TRAINED = True # 其他配置保持不变
  TTA_TIMES = 5
  ```
- Step 3: 启动预测脚本

  ```shell
  python run.py -m inf-cross -p ./dataset/testB
  ```

  预测结果保留在 `./analysis/result/Photo_Guide/v6.0-pretrained-fake`下，包含概率平均和硬投票结果。*注意*：提交时需要删除结果文件的最后8列（概率值）。

## 总结

该赛道受限于数据质量精度暂时没有突破90，总的来说难度不大，但是可做的点不是很多，尝试的许多trick都没发挥作用，后续可考虑多模融合以进一步提分。

*注意*：若代码审查遇到问题请联系我（石军），邮箱：shijun18@mail.ustc.edu.cn
